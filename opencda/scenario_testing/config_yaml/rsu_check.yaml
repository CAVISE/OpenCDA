description: |-
  Copyright 2021 <UCLA Mobility Lab>
  Author: Runsheng Xu <rxx3386@ucla.edu>
  Content: This is the scenario testing configuration file for single vehicle full-stack system in town06 with co-simulation

world:
  town: Town06

blueprint:
  use_multi_class_bp: true
  bp_meta_path: "opencda/assets/blueprint_meta/bbx_stats_0915.json" # Define the path for loading the blueprint metadata for defining the class of each blueprint
  # Define blueprint type sample probabilities
  bp_class_sample_prob:
    car: 0.5
    truck: 0.1
    bus: 0.1
    bicycle: 0.1
    motorcycle: 0.1
    
rsu_base:
  sensing:
    perception:
      activate: false # when not activated, objects positions will be retrieved from server directly
      camera:
        visualize: 0 # how many camera images need to be visualized. 0 means no visualization for camera
        num: 4 # how many cameras are mounted on the vehicle. Maximum 3(frontal, left and right cameras)
        # relative positions (x,y,z,yaw) of the camera. len(positions) should be equal to camera num
        positions:
          - [2.5, 0, 1.0, 0]
          - [0.0, 0.3, 1.8, 100]
          - [0.0, -0.3, 1.8, -100]
          - [-2.0, 0.0, 1.5, 180]
      lidar: # lidar sensor configuration, check CARLA sensor reference for more details
        visualize: false
        channels: 128
        range: 120
        points_per_second: 5000000
        rotation_frequency: 20 # the simulation is 20 fps
        upper_fov: 20
        lower_fov: -90
        dropoff_general_rate: 0.3
        dropoff_intensity_limit: 0.7
        dropoff_zero_intensity: 0.4
        noise_stddev: 0.02
    localization:
      activate: false # when not activated, ego position will be retrieved from server directly
      dt: ${world.fixed_delta_seconds} # used for kalman filter
      gnss: # gnss sensor configuration
        noise_alt_stddev: 0.05
        noise_lat_stddev: 3e-6
        noise_lon_stddev: 3e-6


# First define the basic parameters of the vehicles
vehicle_base:
  sensing:
    perception:
      activate: false # when not activated, objects positions will be retrieved from server directly
      camera:
        visualize: 0 # how many camera images need to be visualized. 0 means no visualization for camera
        num: 4 # how many cameras are mounted on the vehicle. Maximum 3(frontal, left and right cameras)
        # relative positions (x,y,z,yaw) of the camera. len(positions) should be equal to camera num
        positions:
          - [2.5, 0, 1.0, 0]
          - [0.0, 0.3, 1.8, 100]
          - [0.0, -0.3, 1.8, -100]
          - [-2.0, 0.0, 1.5, 180]
      lidar: # lidar sensor configuration, check CARLA sensor reference for more details
        visualize: false
        channels: 32
        range: 120
        points_per_second: 1000000
        rotation_frequency: 20 # the simulation is 20 fps
        upper_fov: 2
        lower_fov: -25
        dropoff_general_rate: 0.3
        dropoff_intensity_limit: 0.7
        dropoff_zero_intensity: 0.4
        noise_stddev: 0.02

    localization:
      activate: false # when not activated, ego position will be retrieved from server directly
      debug_helper:
        show_animation: false # whether to show real-time trajectory plotting

  behavior:
    ignore_traffic_light: false # whether to ignore traffic light
    collision_time_ahead: 2.0 # used for collision checking
    local_planner:
      debug_trajectory: false
      debug: false

# define sumo simulation setting for traffic generation
sumo:
  port: 3000
  host: sumo
  gui: true
  client_order: 2
  step_length: ${world.fixed_delta_seconds}

scenario:
  rsu_list:
    - name: rsu1
      spawn_position: [16.292295, 60.521175, 2, 0, 0, 0]
      id: -1
    - name: rsu2
      spawn_position: [-16.29, 36.37, 2, 0, 0, 0]
      id: -2

  single_cav_list:
    - name: cav1
      spawn_position: [7.61, 185.65, 0.3, 0, -90, 0]
      destination: [-6.09, 67.87, 1.71]
      id: 100
    - name: cav2
      spawn_position: [-147.66, 49.19, 0.3, 0, 0, 0]
      destination: [375.14, 48.54, 1.05]
      id: 200
